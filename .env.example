# Backend Service
SERVER_MAIN_PORT=http://main:5000
SERVER_ENCODER=http://encoder:5001/encode
SERVER_MODEL=http://model:5002/generate-reply
SERVER_FILTER=http://filter-model:5003/generate-reply
# json list
SERVER_FRONTEND=[https://<ip>/]
LLAMA_SERVER=http://llama-server:8080/v1/chat/completions
CyberSync_DatabaseUri=<uri>

PIPE_CONFIG=pipe_config.json
TOKENIZER_CONFIG=tokenizer_config.json
JWT_SECRET=<value>
HF_HUB_DISABLE_SYMLINKS_WARNING=1

_AI_MODEL=distilgpt2
_AI_MODEL=deepseek-ai
_AI_MODEL=llama
_AI_MODEL=inference_qwen
_AI_MODEL=qwen
AI_MODEL=groq

CHUNK_SIZE_BYTES=1048576
CHUNK_OFFSET_BYTES=28

SENTENCE_TRANSFORMER_MODEL=<model>

DEBUG=<0 or 1>

CONTEXT_SCORE_GT=<float 0 - 1>
HF_TOKEN=<value>

# cyber-education-platform / backend (partial)
OPENAI_API_KEY=<value>
ANTHROPIC_API_KEY=<value>
GROQ_API_KEY=<value>

# Database
POSTGRES_DB=<value>
POSTGRES_USER=<value>
POSTGRES_PASSWORD=<value>

# JWT Secret ()
JWT_SECRET=<value>

# VNC Password
VNC_PASSWORD=<value>
# depends on the environment
VITE_CYBER_EDUCATION_API_BASE_URL=<value>
VITE_CYBER_EDUCATION_VNC_BASE_URL=/cyber-education/vnc
_FRONTEND_ORIGIN=https://<ip>/
FRONTEND_ORIGIN=https://localhost:5173/


VITE_API_URL=http://localhost:3000
_VITE_VNC_URL=http://localhost:6080
VITE_VNC_URL=https://<ip>/vnc

VITE_PRODUCTION_ENV=<0 or 1>

BACKEND_MAIN_API_URL=http://main:5000/api
SERVERURL=https://<ip>
# or for local
_SERVERURL=http://localhost
